"""Tests for optional production enhancements.

Tests verify:
1. Eager loading methods in DataProductRepository
2. Enhanced Pydantic validation config
3. Composite index creation (verified at schema level)
"""

from __future__ import annotations

from datetime import datetime, timezone

import pytest
from pydantic import ValidationError
from sqlalchemy import create_engine
from sqlmodel import Session, SQLModel

from tolteca_db.constants import DataProdType, ProductKind
from tolteca_db.db.repository import DataProductRepository
from tolteca_db.models.metadata import DataProdMetaBase, RawObsMeta
from tolteca_db.models.orm import Base, DataProduct, DataProductStorage, Location


def utc_now_iso() -> str:
    """Return current UTC time as ISO 8601 string (Python 3.13 compatible)."""
    return datetime.now(tz=timezone.utc).isoformat()


@pytest.fixture
def in_memory_db():
    """Create in-memory SQLite database for testing."""
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    yield engine
    # Properly dispose engine to prevent unclosed connection warnings
    engine.dispose()


@pytest.fixture
def session(in_memory_db):
    """Create database session."""
    with Session(in_memory_db) as session:
        yield session


@pytest.fixture
def sample_product(session):
    """Create sample product with storage locations."""
    # Create location (timestamps auto-generated by database)
    location = Location(
        location_id="test_loc",
        label="Test Location",
        site_code="TEST",
        priority=1,
        meta={}
    )
    session.add(location)
    
    # Create product (timestamps auto-generated by database)
    product = DataProduct(
        product_id="test_product_123",
        base_type="raw_obs",
        name="test_obs_001",
        product_kind=ProductKind.RAW.value,
        meta={}
    )
    session.add(product)
    
    # Create storage (timestamps auto-generated by database)
    storage = DataProductStorage(
        product_id="test_product_123",
        location_id="test_loc",
        storage_key="file:///data/test.fits",
        role="PRIMARY",
        size=1024
    )
    session.add(storage)
    
    session.commit()
    return product.product_id


class TestEagerLoading:
    """Test eager loading methods for N+1 query prevention."""

    def test_get_with_storage(self, session, sample_product):
        """Test getting product with storage eagerly loaded."""
        repo = DataProductRepository(session, DataProduct)
        product = repo.get_with_storage(sample_product)
        
        assert product is not None
        assert product.product_id == sample_product
        # Access storage_locations - should not trigger additional query
        assert len(product.storage_locations) == 1
        assert product.storage_locations[0].storage_key == "file:///data/test.fits"

    def test_get_with_flags(self, session, sample_product):
        """Test getting product with flags eagerly loaded."""
        repo = DataProductRepository(session, DataProduct)
        product = repo.get_with_flags(sample_product)
        
        assert product is not None
        assert product.product_id == sample_product
        # Access flags - should not trigger additional query
        assert len(product.flags) == 0  # No flags added in fixture

    def test_get_with_all_relations(self, session, sample_product):
        """Test getting product with all relationships eagerly loaded."""
        repo = DataProductRepository(session, DataProduct)
        product = repo.get_with_all_relations(sample_product)
        
        assert product is not None
        assert len(product.storage_locations) == 1
        assert len(product.flags) == 0

    def test_list_with_storage(self, session, sample_product):
        """Test listing products with storage eagerly loaded."""
        repo = DataProductRepository(session, DataProduct)
        products = repo.list_with_storage(base_type="raw_obs", limit=10)
        
        assert len(products) == 1
        assert products[0].product_id == sample_product
        # Access storage without N+1 queries
        assert len(products[0].storage_locations) == 1

    def test_list_with_storage_no_filter(self, session, sample_product):
        """Test listing all products with storage."""
        repo = DataProductRepository(session, DataProduct)
        products = repo.list_with_storage()
        
        assert len(products) == 1
        assert products[0].storage_locations[0].location_id == "test_loc"


class TestEnhancedPydanticValidation:
    """Test enhanced Pydantic validation configuration."""

    def test_model_config_validation(self):
        """Test that model_config has enhanced settings."""
        config = DataProdMetaBase.model_config
        
        # Verify enhanced validation settings
        assert config["use_enum_values"] is True
        assert config["validate_default"] is True
        assert config["validate_assignment"] is True
        assert config["extra"] == "forbid"

    def test_extra_forbid_rejects_unknown_fields(self):
        """Test that extra='forbid' rejects unknown fields."""
        with pytest.raises(ValidationError) as exc_info:
            DataProdMetaBase(
                name="test",
                data_prod_type=DataProdType.DP_RAW_OBS,
                unknown_field="should_fail"
            )
        
        # Verify error mentions unexpected field
        assert "unknown_field" in str(exc_info.value)

    def test_validate_assignment_on_change(self):
        """Test that validate_assignment re-validates on attribute changes."""
        meta = RawObsMeta(
            name="test_obs",
            data_prod_type=DataProdType.DP_RAW_OBS,
            master="toltec",
            obsnum=12345,
            subobsnum=0,
            scannum=1,
            data_kind=1
        )
        
        # Valid change
        meta.obsnum = 54321
        assert meta.obsnum == 54321
        
        # Invalid change should raise ValidationError
        with pytest.raises(ValidationError):
            meta.obsnum = "not_an_int"  # type: ignore

    def test_validate_default_validates_defaults(self):
        """Test that validate_default validates default values."""
        # This test verifies the config is set correctly
        # Actual validation happens at model definition time
        meta = RawObsMeta(
            name="test",
            data_prod_type=DataProdType.DP_RAW_OBS,
            master="toltec",
            obsnum=1,
            subobsnum=0,
            scannum=0,
            data_kind=1
        )
        
        # Optional fields with None default should validate
        assert meta.nw_id is None
        assert meta.obs_goal is None


class TestCompositeIndex:
    """Test composite index creation (schema-level verification)."""

    def test_composite_index_exists(self, in_memory_db):
        """Verify composite index exists in schema."""
        # Get table metadata
        inspector = create_engine("sqlite:///:memory:").pool._creator
        metadata = Base.metadata
        data_product_table = metadata.tables["data_product"]
        
        # Check for composite index
        index_names = [idx.name for idx in data_product_table.indexes]
        
        # Verify our new composite index
        assert "ix_base_type_availability" in index_names
        
        # Verify index columns
        composite_index = next(
            idx for idx in data_product_table.indexes
            if idx.name == "ix_base_type_availability"
        )
        column_names = [col.name for col in composite_index.columns]
        assert column_names == ["base_type", "availability_state"]

    def test_existing_indexes_preserved(self, in_memory_db):
        """Verify existing indexes are still present."""
        metadata = Base.metadata
        data_product_table = metadata.tables["data_product"]
        index_names = [idx.name for idx in data_product_table.indexes]
        
        # Original composite index should still exist
        assert "ix_product_kind_status" in index_names
